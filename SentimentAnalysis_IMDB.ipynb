{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IGLEvLAdUFFa"
      },
      "source": [
        "# IMDB SENTIMENT ANALYSIS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JBOHB0qzUC5B"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Sentiment analysis** is a subject that is one of the most targeted applications in NLP and with interesting applications in everyday life.\n",
        "\n",
        "For this task, we will use the IMDB Dataset database, available from kaggle [at this address](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews). The dataset contains 50000 *reviews* of different films, with each review classified as positive or negative. As it is a dataset with a label for each sentence and with only two possible classes for this label, we can say that we are dealing with a binary classification task for texts.\n",
        "\n",
        "A Word2Vec model was formulated to generate Word Embeddings used as input to two different neural network architectures for text classification - CNN and LSTM - for comparison purposes.\n",
        "\n",
        "We started by importing the libraries used throughout this work and defining *seeds* to make the work as reproducible as possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX3GB6W58vGw",
        "outputId": "36706df3-9192-48cd-cc1c-b8fe2d02d157"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import pad_sequences\n",
        "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string\n",
        "from gensim.models import word2vec\n",
        "from gensim.test.utils import datapath\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from numpy.random import seed\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "from sklearn.metrics import classification_report\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "seed(1)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mti0dLf3TvZ7"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One of the most important parts in any NLP task - and in data science as a whole - is the data pre-processing, in order to make data more \"clean\" and interpretable by the networks architectures.\n",
        "\n",
        "Having imported the necessary libraries, we read the data file and quickly visualize the first lines, check if there is any null value for removal and print the *shape* of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHhXJkjE_YJv",
        "outputId": "0d63ab02-6ed7-4e56-c5ed-5cb91891a715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "(50000, 2)\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('./IMDB_Dataset.csv')\n",
        "print(data.isnull().values.any())\n",
        "print(data.shape)\n",
        "print(data.head())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5Un-U4bctLMK"
      },
      "source": [
        "Then we visualize one of the *reviews* - the first one - just to get an idea of the possible preprocessing jobs that can be done. We also print the number of *reviews* classified as positive and negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "TXcpSIcAAaMr",
        "outputId": "273e11d0-0c6a-455d-efa2-b707f57e452e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           review\n",
              "sentiment        \n",
              "negative    25000\n",
              "positive    25000"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(data.iloc[1, 0])\n",
        "data.groupby('sentiment').count()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "loHh_wixuEEF"
      },
      "source": [
        "First, the equality in the division of *reviews* according to classes is highlighted. This is because Kaggle's dataset is only a representative sample of the original dataset (which contains more *reviews*) thus maintaining a balance between classes that saves us from having to deal with problems of unbalanced classes.\n",
        "\n",
        "Then we create a function with the preprocessing operations used. The code provides comments about each operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFh-zaFRh2Tz",
        "outputId": "817db733-d1e8-4fc2-d65f-e725afff4479"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\phara\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\phara\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6FbyRfvwB907"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(sen):\n",
        "  # Removing html tags\n",
        "  sentence = re.sub('<[^>]+>', '', sen).lower()\n",
        "\n",
        "  # Remove punctuations and numbers\n",
        "  sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "  # Single character removal\n",
        "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "  # Removing multiple spaces\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "  # Removing abreviated verbs\n",
        "  sentence = re.sub(\"\\'ll\", ' will', sentence)\n",
        "  sentence = re.sub(\"\\'ve\", ' have', sentence)\n",
        "  sentence = re.sub(\"\\'s\", ' is', sentence)\n",
        "\n",
        "  # Removing stopwords\n",
        "  sentence = remove_stopwords(sentence)\n",
        "\n",
        "  # Lematize words\n",
        "  # word_list = nltk.word_tokenize(sentence)\n",
        "  # sentence = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
        "\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "G9hwO484C2JT"
      },
      "outputs": [],
      "source": [
        "sentences = list(data['review'])\n",
        "X = [preprocess_text(sen) for sen in sentences]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UiuxsnUpu0Pg"
      },
      "source": [
        "Applying the chosen pre-processing operations, we have the following sentence as a result - for the case shown above. You can see much smoother text than the original, with all lowercase letters, no links, verb abbreviations (like *We will = We'll*), no presence of *stop words* (like *the*), words of single character or punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "UY6UpoAXDHbd",
        "outputId": "280c5a21-e21b-4b96-9d8a-f458aac7a98f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'wonderful little production filming technique unassuming old time bbc fashion gives comforting discomforting sense realism entire piece actors extremely chosen michael sheen got polari voices pat truly seamless editing guided references williams diary entries worth watching terrificly written performed piece masterful production great master comedy life realism comes home little things fantasy guard use traditional dream techniques remains solid disappears plays knowledge senses particularly scenes concerning orton halliwell sets particularly flat halliwell murals decorating surface terribly'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "paNeJyp4vprN"
      },
      "source": [
        "So far, we have all *reiews* pre-processed but still in sentence form, that is, words. We need to use some kind of numerical identification for each word so that the model can interpret them. To do so, we will use Word2Vec to generate vectors of words, that is, represent each word through an *n*-dimensional vector."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TstCSTNTW6bW"
      },
      "source": [
        "## Word2Vec - Skipgram/CBOW"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's train a CBOW to generate word vectors. For this task, several parameters were varied in order to try to find the best model defined by solving analogies with the 'question-words.txt' data. Both Skipgram and CBOW were used, with only the *setup* with the best result being presented in this code.\n",
        "\n",
        "It should be noted that although the objective of this work is not to solve analogies and the database does not contain all the words that the 'question-words' file contains, the method can still be used to assess whether or not the trained model generates vectors of words that preserve the semantic relations among themselves.\n",
        "\n",
        "PARAMETERS TESTED:\n",
        "- Array size (num_features) = (100, 150, 200 and 500)\n",
        "- Window (window) = (5, 10, 15, 20)\n",
        "- Min_count = (1, 3, 6, 9, 12)\n",
        "- Negative sampling = (0, 5)\n",
        "- Ns_exponent: We do not vary this parameter, leaving it at the *default* value of the original paper.\n",
        "- sg = 0 for CBOW / 1 for Skipgram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "T7VC6lNdVmzv"
      },
      "outputs": [],
      "source": [
        "sentences = []\n",
        "for sentence in X:\n",
        "  foo = sentence.split()\n",
        "  sentences.append(foo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzA-dQ7OW7vF",
        "outputId": "2e966ae7-1dac-44c8-f479-c488b9cb76bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-21 01:49:53,785 : INFO : collecting all words and their counts\n",
            "2023-06-21 01:49:53,785 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2023-06-21 01:49:53,979 : INFO : PROGRESS: at sentence #10000, processed 1029215 words, keeping 51874 word types\n",
            "2023-06-21 01:49:54,156 : INFO : PROGRESS: at sentence #20000, processed 2058239 words, keeping 69046 word types\n",
            "2023-06-21 01:49:54,340 : INFO : PROGRESS: at sentence #30000, processed 3087226 words, keeping 81513 word types\n",
            "2023-06-21 01:49:54,526 : INFO : PROGRESS: at sentence #40000, processed 4114778 words, keeping 91946 word types\n",
            "2023-06-21 01:49:54,730 : INFO : collected 101065 word types from a corpus of 5146984 raw words and 50000 sentences\n",
            "2023-06-21 01:49:54,731 : INFO : Creating a fresh vocabulary\n",
            "2023-06-21 01:49:55,026 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 101065 unique words (100.0%% of original 101065, drops 0)', 'datetime': '2023-06-21T01:49:55.026804', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
            "2023-06-21 01:49:55,027 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 5146984 word corpus (100.0%% of original 5146984, drops 0)', 'datetime': '2023-06-21T01:49:55.027305', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
            "2023-06-21 01:49:55,508 : INFO : deleting the raw counts dictionary of 101065 items\n",
            "2023-06-21 01:49:55,510 : INFO : sample=0.001 downsamples 16 most-common words\n",
            "2023-06-21 01:49:55,510 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4967550.44793487 word corpus (96.5%% of prior 5146984)', 'datetime': '2023-06-21T01:49:55.510807', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
            "2023-06-21 01:49:55,558 : INFO : constructing a huffman tree from 101065 words\n",
            "2023-06-21 01:49:58,299 : INFO : built huffman tree with maximum node depth 23\n",
            "2023-06-21 01:49:58,321 : INFO : estimated required memory for 101065 words and 100 dimensions: 151597500 bytes\n",
            "2023-06-21 01:49:58,321 : INFO : resetting layer weights\n",
            "2023-06-21 01:49:58,357 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-06-21T01:49:58.357302', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
            "2023-06-21 01:49:58,357 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 101065 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=0 window=10 shrink_windows=True', 'datetime': '2023-06-21T01:49:58.357802', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
            "2023-06-21 01:49:59,362 : INFO : EPOCH 1 - PROGRESS: at 26.89% examples, 1337082 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:00,370 : INFO : EPOCH 1 - PROGRESS: at 54.54% examples, 1348223 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:01,370 : INFO : EPOCH 1 - PROGRESS: at 82.54% examples, 1361141 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:02,009 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2023-06-21 01:50:02,014 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2023-06-21 01:50:02,017 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2023-06-21 01:50:02,020 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2023-06-21 01:50:02,021 : INFO : EPOCH - 1 : training on 5146984 raw words (4967277 effective words) took 3.7s, 1357318 effective words/s\n",
            "2023-06-21 01:50:03,032 : INFO : EPOCH 2 - PROGRESS: at 27.09% examples, 1338069 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:04,042 : INFO : EPOCH 2 - PROGRESS: at 54.34% examples, 1336954 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:05,052 : INFO : EPOCH 2 - PROGRESS: at 82.95% examples, 1359259 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:05,618 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2023-06-21 01:50:05,624 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2023-06-21 01:50:05,624 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2023-06-21 01:50:05,626 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2023-06-21 01:50:05,627 : INFO : EPOCH - 2 : training on 5146984 raw words (4967148 effective words) took 3.6s, 1378685 effective words/s\n",
            "2023-06-21 01:50:06,633 : INFO : EPOCH 3 - PROGRESS: at 26.89% examples, 1335177 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:07,635 : INFO : EPOCH 3 - PROGRESS: at 54.90% examples, 1360097 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:08,641 : INFO : EPOCH 3 - PROGRESS: at 82.76% examples, 1363365 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:09,257 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2023-06-21 01:50:09,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2023-06-21 01:50:09,267 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2023-06-21 01:50:09,269 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2023-06-21 01:50:09,269 : INFO : EPOCH - 3 : training on 5146984 raw words (4967567 effective words) took 3.6s, 1364877 effective words/s\n",
            "2023-06-21 01:50:10,279 : INFO : EPOCH 4 - PROGRESS: at 27.27% examples, 1350106 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:11,280 : INFO : EPOCH 4 - PROGRESS: at 55.86% examples, 1382693 words/s, in_qsize 8, out_qsize 1\n",
            "2023-06-21 01:50:12,282 : INFO : EPOCH 4 - PROGRESS: at 83.90% examples, 1383863 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:12,859 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2023-06-21 01:50:12,869 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2023-06-21 01:50:12,877 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2023-06-21 01:50:12,879 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2023-06-21 01:50:12,879 : INFO : EPOCH - 4 : training on 5146984 raw words (4967953 effective words) took 3.6s, 1377493 effective words/s\n",
            "2023-06-21 01:50:13,896 : INFO : EPOCH 5 - PROGRESS: at 26.89% examples, 1326384 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:14,899 : INFO : EPOCH 5 - PROGRESS: at 54.34% examples, 1341168 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:15,903 : INFO : EPOCH 5 - PROGRESS: at 82.95% examples, 1364503 words/s, in_qsize 7, out_qsize 0\n",
            "2023-06-21 01:50:16,494 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2023-06-21 01:50:16,504 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2023-06-21 01:50:16,509 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2023-06-21 01:50:16,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2023-06-21 01:50:16,510 : INFO : EPOCH - 5 : training on 5146984 raw words (4967356 effective words) took 3.6s, 1370786 effective words/s\n",
            "2023-06-21 01:50:16,511 : INFO : Word2Vec lifecycle event {'msg': 'training on 25734920 raw words (24837301 effective words) took 18.2s, 1368219 effective words/s', 'datetime': '2023-06-21T01:50:16.511305', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
            "2023-06-21 01:50:16,512 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=101065, vector_size=100, alpha=0.025)', 'datetime': '2023-06-21T01:50:16.512307', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
          ]
        }
      ],
      "source": [
        "context_size = 10\n",
        "min_word_count = 1\n",
        "num_features = 100\n",
        "num_workers = 4\n",
        "negative = 0\n",
        "hs = 1\n",
        "expoent = 0.75\n",
        "sg = 0\n",
        "\n",
        "model_word2vec = word2vec.Word2Vec(sentences, sg=sg, vector_size=num_features, window=context_size, min_count=min_word_count, workers=num_workers,\n",
        "                                   sorted_vocab=1, negative=negative, seed=1, ns_exponent=expoent, hs=hs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_word2vec = model_word2vec.wv.key_to_index\n",
        "embedding_matrix = model_word2vec.wv.vectors"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UodpvPPox-kc"
      },
      "source": [
        "To start evaluating the performance of the model, we print the words most similar to the word *queen*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXzDMKQ7Vmux",
        "outputId": "f7e19a56-7ca5-41c7-823a-b2a5fb0cf845"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('princess', 0.5960198044776917),\n",
              " ('aaliyah', 0.5180010795593262),\n",
              " ('blond', 0.5145314931869507),\n",
              " ('internecine', 0.4841921925544739),\n",
              " ('monarch', 0.4653262794017792),\n",
              " ('gedren', 0.4603918790817261),\n",
              " ('sheeba', 0.4564395546913147),\n",
              " ('tarn', 0.45639118552207947),\n",
              " ('mab', 0.4541601240634918),\n",
              " ('hottie', 0.4501498341560364)]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_word2vec.wv.most_similar('queen')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-awjMVtCyIrU"
      },
      "source": [
        "We also analyzed the ability to perform operations with vectors using the classic operation `KING + WOMAN - MAN`, which should result in `QUEEN`. We note that the generated model, even if it does not point out the correct answer as the most similar, contains it among the 3 most similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3mCeaLgVmqY",
        "outputId": "288ac9f1-b408-409e-af86-69bbb552ac55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('queen', 0.5727253556251526),\n",
              " ('togther', 0.4883419871330261),\n",
              " ('boleyn', 0.4720785319805145)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# printamos os 3 primeiros resultados (nem sempre QUEEN é o primeiro)\n",
        "model_word2vec.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8uvmQvmIyc52"
      },
      "source": [
        "Some similarities performance check using *questions-words.txt* file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd88v7Y6Vmlk",
        "outputId": "04d0fc44-1c3e-405b-c898-238e1897723d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-21 01:50:16,640 : INFO : Evaluating word analogies for top 300000 words in the model on c:\\Users\\phara\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\./questions-words.txt\n",
            "2023-06-21 01:50:17,847 : INFO : capital-common-countries: 5.8% (27/462)\n",
            "2023-06-21 01:50:20,710 : INFO : capital-world: 2.4% (27/1124)\n",
            "2023-06-21 01:50:21,027 : INFO : currency: 0.0% (0/128)\n",
            "2023-06-21 01:50:26,313 : INFO : city-in-state: 0.6% (13/2056)\n",
            "2023-06-21 01:50:27,284 : INFO : family: 35.5% (135/380)\n",
            "2023-06-21 01:50:29,530 : INFO : gram1-adjective-to-adverb: 2.5% (22/870)\n",
            "2023-06-21 01:50:31,470 : INFO : gram2-opposite: 0.8% (6/756)\n",
            "2023-06-21 01:50:34,962 : INFO : gram3-comparative: 10.8% (144/1332)\n",
            "2023-06-21 01:50:37,762 : INFO : gram4-superlative: 4.2% (47/1122)\n",
            "2023-06-21 01:50:39,538 : INFO : gram5-present-participle: 14.1% (99/702)\n",
            "2023-06-21 01:50:43,282 : INFO : gram6-nationality-adjective: 12.3% (178/1445)\n",
            "2023-06-21 01:50:47,162 : INFO : gram7-past-tense: 13.2% (206/1560)\n",
            "2023-06-21 01:50:50,451 : INFO : gram8-plural: 13.1% (165/1260)\n",
            "2023-06-21 01:50:52,006 : INFO : gram9-plural-verbs: 12.0% (72/600)\n",
            "2023-06-21 01:50:52,007 : INFO : Quadruplets with out-of-vocabulary words: 29.4%\n",
            "2023-06-21 01:50:52,008 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
            "2023-06-21 01:50:52,008 : INFO : Total accuracy: 8.3% (1141/13797)\n"
          ]
        }
      ],
      "source": [
        "similarities = model_word2vec.wv.evaluate_word_analogies(datapath('./questions-words.txt'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kVpjDNV1UTRJ"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jYHbfRJGy5NN"
      },
      "source": [
        "Once the data has been pre-processed in order to designate a pattern for the sentences and the word vectors to be used have been defined, we move on to the data preparation stage for the final models - LSTM and CNN.\n",
        "In this step, we Tokenize the words of the sentences (*reviews*) in order to assign a unique identifier to each word. We also transform the classes as follows:\n",
        "\n",
        "- 'positive' = 1\n",
        "- 'negative' = 0\n",
        "\n",
        "Also in this step, we perform the *padding* operation that guarantees that all sentences have the same length, which is a prerequisite for networks such as LSTM and CNN."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rQV4uGGHI8e4"
      },
      "source": [
        "### Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WSRrk5oIDKnA"
      },
      "outputs": [],
      "source": [
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, data['sentiment'])))\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "evEfI7LjIVhz"
      },
      "source": [
        "### Analyzing Reviews Length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "JAJc_zWUJ1p2",
        "outputId": "b31f90d8-9c73-4d77-dfdb-6c30d6d976ab"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "lengths = [len(seq) for seq in X]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(x=lengths)\n",
        "plt.title('Reviews Length Boxplot', fontsize=16)\n",
        "plt.xlabel('Reviews Length', fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w02JaHTyIy8Y"
      },
      "source": [
        "We note that the vast majority of cases have sentence size less than or equal to 200. Based on the size distribution of *reviews* we can use certain values as maximum size for the *padding* operation."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QsOrtBJSIbXs"
      },
      "source": [
        "### Padding/Truncating"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ImIaBQ2jJI17"
      },
      "source": [
        "The padding task consists of transforming all sentences into sentences of the same length by adding (padding) or removing words (truncation).\n",
        "\n",
        "For the `MAX_SIZE` hyperparameter, which concerns the size of sentences after padding or truncation, the tested values were:\n",
        "\n",
        "- `MAX_SIZE` = (200, 300, 500, largest_sentence_size)\n",
        "\n",
        "As in this work we have a classification for each sentence, applying truncation can remove useful words for classifying the *review* as good or bad. After testing the values described above, it was noted in the end that the best result occurs when we perform only *padding*, that is, when we add words with identifier 0 to lengthen short sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WejXPg3KKhZn"
      },
      "outputs": [],
      "source": [
        "MAX_SIZE = len(max(X, key=len))\n",
        "# MAX_SIZE = 200\n",
        "X = pad_sequences(X, padding='pre', maxlen=MAX_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JJNUkfUDIgP0"
      },
      "source": [
        "### Train, Validation, Test Split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H4hRqQZXKA4C"
      },
      "source": [
        "At this point, we have the pre-processed text, with word vectors generated via CBOW and with *padding*. Therefore, we will build the weight matrix to be used in the model, based on the word vectors.\n",
        "\n",
        "Next, we split the dataset into training, validation, and testing. We used 20% of the data as test data and the remaining 80%, 20% as validation and 80% as training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "inIRaxzVNWoW"
      },
      "outputs": [],
      "source": [
        "import contextlib\n",
        "emb_matrix = np.zeros((vocab_size, num_features))\n",
        "\n",
        "for w, i in tokenizer.word_index.items():\n",
        "  if i < vocab_size:\n",
        "    with contextlib.suppress(Exception):\n",
        "      vect = model_word2vec.wv.get_vector(w)\n",
        "      emb_matrix[i] = vect\n",
        "  else:\n",
        "    print('OPA!')\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IZuy7l-FLugF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HIubgU3CUgMh"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rJxINcySKfZ1"
      },
      "source": [
        "As previously mentioned, we will use two models for comparison regarding *reviews* classification, LSTM and CNN.\n",
        "\n",
        "In the section of each model architecture, we present a brief description of its operation, followed by the tested hyperparameter values."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CdoMAOsXIkGc"
      },
      "source": [
        "### LSTM Architecture"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Long short-term memory (LSMT) is a type of recurrent neural network (RNN) architecture with the sequential processing capability transmitting information as a kind of memory. Thus, the network learns not only from the information of each word but also from the sequences of words and their combined meanings.\n",
        "\n",
        "This feature also makes LSTM networks capable of dealing with the *vanishing gradient* problem that occurs when the weights update is so minimal that the weights end up not being changed for some network units.\n",
        "\n",
        "Next, we use a Bidirectional layer, thus making the LSTM able to learn from the future information of a certain word, different from a normal LSTM model, which only sees the past information. Simply put, it's like the model is reading everything that comes before AND AFTER each word to learn the meaning of the contexts that contain it.\n",
        "\n",
        "As our problem consists of a binary classification task, we use the *sigmoid* activation function in the last Dense layer with 1 unit and the *binary_crossentropy* function as *loss*.\n",
        "\n",
        "Note that the first layer of the model is an Embedding layer with the parameter **trainable == False** and with weights equal to the previously generated embedding matrix. With this configuration we guarantee that the word vectors used by the network are those found via CBOW and will not change.\n",
        "\n",
        "At this stage, the varied parameters were:\n",
        "\n",
        "- N_UNITS (LSTM cell size) = 32, 64, 128, 256, 512.\n",
        "- LEARNING_RATE = 0.0001, 0.0005."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmuuJBcFNWfT",
        "outputId": "11199315-1309-4204-cea9-9800044c762f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 100)         10106600  \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 256)              234496    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,341,353\n",
            "Trainable params: 234,753\n",
            "Non-trainable params: 10,106,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(input_dim=vocab_size, output_dim=num_features, weights=[emb_matrix], trainable=False))\n",
        "model_lstm.add(Bidirectional(LSTM(128)))\n",
        "model_lstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_lstm.compile(loss='binary_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
        "\n",
        "model_lstm.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vMX2Fj9-ImnE"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the training process, only the **batch_size** size was varied in order to avoid *overfitting* in some cases or *underfitting* in others, assigning the **batch_size** that best suited each situation. The values used were:\n",
        "\n",
        "- BATCH_SIZE = 64, 128, 256."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqGR4GDhDieV",
        "outputId": "7f02d6b5-58ae-4801-fc4b-220ed157af1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "125/125 [==============================] - 40s 291ms/step - loss: 0.5606 - accuracy: 0.7269 - val_loss: 0.4245 - val_accuracy: 0.8121\n",
            "Epoch 2/10\n",
            " 12/125 [=>............................] - ETA: 30s - loss: 0.4148 - accuracy: 0.8197"
          ]
        }
      ],
      "source": [
        "history_lstm = model_lstm.fit(X_train, y_train, batch_size=256, epochs=10, validation_data=(X_val, y_val))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KXkh59YeXktS"
      },
      "source": [
        "We then plotted the loss function and accuracy graphs during training for the training and validation sets, providing a visual assessment tool for model behavior for both data sets and for the difference in model performance on each case. Thus, we can verify evidence of the existence or not of *overfitting*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "Ed287CX5-fn5",
        "outputId": "3da5ff5f-53d0-4ab1-9142-ac3e3ed361a3"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "fig.suptitle('TRAINING HISTORY FOR LSTM MODEL', fontsize=18)\n",
        "\n",
        "ax1.plot(history_lstm.history['accuracy'])\n",
        "ax1.plot(history_lstm.history['val_accuracy'])\n",
        "plt.sca(ax1)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.legend(['Train', 'Validation'], loc='upper left', fontsize=14)\n",
        "plt.title('Accuracy history', fontsize=16)\n",
        "\n",
        "ax2.plot(history_lstm.history['loss'])\n",
        "ax2.plot(history_lstm.history['val_loss'])\n",
        "plt.sca(ax2)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.legend(['Train', 'Validation'], loc='upper right', fontsize=14)\n",
        "plt.title('Loss History', fontsize=16)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2vUNJPkTIp85"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vh37WuaxYJqf"
      },
      "source": [
        "Evaluating the performance of the model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esbf1yoD-mFw",
        "outputId": "33f1073d-be34-4c92-8450-3886f324e684"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model_lstm.evaluate(X_test, y_test, verbose = 1)\n",
        "print(\"Loss: {0},\\nAccuracy: {1}\".format(loss, accuracy))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v8OsKCfXYPfe"
      },
      "source": [
        "We noticed that the model manages to reach an accuracy of 88% in the test set, which is not far from the performance in the other sets. This shows the good generalization ability of the model trained using the word vectors generated by CBOW."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rRim-GtOTchB"
      },
      "source": [
        "### CNN Architecture"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ciAmUX6FiASs"
      },
      "source": [
        "In this section we use a CNN (Convolutional Neural Network) architecture. CNN-type neural networks are widely used for text and image classification tasks and other applications. Thus, we will use a CNN with a simple architecture and compare the results obtained with those of the LSTM model.\n",
        "\n",
        "The architecture used here consists of a non-trainable Embedding layer, with weights equal to the embedding matrix calculated with CBOW, followed by a 1D convolution layer - since we are dealing with texts - with a MaxPooling operation that is also 1D. The convolution layer is repeated and we use a 1D GlobalMaxPooling. Finally, a Dense (*fully connected*) layer, with sigmoidal activation and *binary_crossentropy* as a loss function.\n",
        "\n",
        "The changed parameters and tested values are:\n",
        "\n",
        "- CNN layer 1: 32, 64, 128.\n",
        "- CNN layer 2: 64, 128, 256.\n",
        "- Learning_Rate: 0.0001, 0.0005\n",
        "\n",
        "Next, the training and testing process presents codes very similar to those of the LSTM methodology."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6Oe6zTiUx_V",
        "outputId": "f136c3c5-1da7-48d1-f683-aa00efaef183"
      },
      "outputs": [],
      "source": [
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import GlobalMaxPooling1D, Flatten\n",
        "\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Embedding(input_dim=vocab_size, output_dim=num_features, weights=[emb_matrix], input_length=MAX_SIZE, trainable=False))\n",
        "model_cnn.add(Conv1D(64, 3, padding='same', activation='relu'))\n",
        "model_cnn.add(MaxPooling1D())\n",
        "model_cnn.add(Conv1D(128, 3, padding='same', activation='relu'))\n",
        "model_cnn.add(GlobalMaxPooling1D())\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "model_cnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_cnn.compile(loss='binary_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
        "model_cnn.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dNYqwELzThol"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qKCg9z1XHUR",
        "outputId": "baafdabd-fa83-4e0c-914a-a160e5fd792c"
      },
      "outputs": [],
      "source": [
        "history_cnn = model_cnn.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "HccicvtHXJXL",
        "outputId": "b901c51f-25cb-4500-aa89-b9fd3fa20493"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "fig.suptitle('TRAINING HISTORY FOR CNN MODEL', fontsize=18)\n",
        "\n",
        "ax1.plot(history_cnn.history['accuracy'])\n",
        "ax1.plot(history_cnn.history['val_accuracy'])\n",
        "plt.sca(ax1)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.legend(['Train', 'Validation'], loc='upper left', fontsize=14)\n",
        "plt.title('Accuracy history', fontsize=16)\n",
        "\n",
        "ax2.plot(history_cnn.history['loss'])\n",
        "ax2.plot(history_cnn.history['val_loss'])\n",
        "plt.sca(ax2)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.legend(['Train', 'Validation'], loc='upper right', fontsize=14)\n",
        "plt.title('Loss History', fontsize=16)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GrZaS8bmTi-W"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtGwPuTRXPwt",
        "outputId": "30f5b9b4-6b78-449f-9742-a4e659727e47"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model_cnn.evaluate(X_test, y_test, verbose = 1)\n",
        "print(\"Loss: {0},\\nAccuracy: {1}\".format(loss, accuracy))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4j1BaiE-kCZR"
      },
      "source": [
        "After training and evaluating the models, we can see that the LSTM, probably due to its sequential processing capability, outperformed the CNN architecture in general. Although the results were very close, it was more difficult to tune the CNN model than for the LSTM case. Still, CNN networks rarely exceeded the accuracy values obtained with an LSTM network for the test bench. CNN also showed a greater tendency to overfit compared to LSTM."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2F0Zzgmkk5o"
      },
      "source": [
        "### Comparison"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xhhVJ_LukpKM"
      },
      "source": [
        "In this section, we plot the confusion matrix of the two fitted models, in order to try to compare their performances. For this, we take the predictions of each model, and define the class based on the given probability. Probabilities greater than 0.5 are classified as 1, ie *review* 'positive', and otherwise are classified as 0, *review* 'negative'.\n",
        "\n",
        "We then used the **confusion_matrix** function to generate the confusion matrices, and calculated the proportion of each case based on the total. Thus, we have the accuracy per class on the main diagonal of each matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EBfS7Rlnhpc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "pred_lstm = model_lstm.predict(X_test)\n",
        "pred_lstm = np.where(pred_lstm > 0.5, 1, 0).flatten()\n",
        "pred_cnn = model_cnn.predict(X_test)\n",
        "pred_cnn = np.where(pred_cnn > 0.5, 1, 0).flatten()\n",
        "\n",
        "cmat_lstm = confusion_matrix(y_test, pred_lstm)\n",
        "cmat_cnn = confusion_matrix(y_test, pred_cnn)\n",
        "\n",
        "def get_proportion(foo):\n",
        "  somas = foo.sum(axis=1)\n",
        "  for i in range(len(foo)):\n",
        "    for j in range(len(foo)):\n",
        "      foo.iloc[i,j] = foo.iloc[i,j]/somas[i]\n",
        "  return foo\n",
        "\n",
        "cmat_lstm = get_proportion(pd.DataFrame(cmat_lstm))\n",
        "cmat_cnn = get_proportion(pd.DataFrame(cmat_cnn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "dJvaY0fUpXLE",
        "outputId": "4c0c04b3-4169-43e0-f09f-fa2ce66e440c"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
        "\n",
        "sns.heatmap(cmat_lstm.round(2), annot=True, ax=ax1)\n",
        "sns.heatmap(cmat_cnn.round(2), annot=True, ax=ax2)\n",
        "\n",
        "a = list(range(2))\n",
        "a = [x+0.5 for x in a]\n",
        "\n",
        "plt.sca(ax1)\n",
        "plt.title('LSTM Confusion Matrix', fontsize=16)\n",
        "plt.yticks(a, ['Negative', 'Positive'], fontsize=12)\n",
        "plt.xticks(a, ['Negative', 'Positive'], fontsize=12)\n",
        "plt.ylabel('Real Label', fontsize=14)\n",
        "plt.xlabel('Predicted Label', fontsize=14)\n",
        "\n",
        "plt.sca(ax2)\n",
        "plt.title('CNN Confusion Matrix', fontsize=16)\n",
        "plt.yticks(a, ['Negative', 'Positive'], fontsize=12)\n",
        "plt.xticks(a, ['Negative', 'Positive'], fontsize=12)\n",
        "plt.ylabel('Real Label', fontsize=14)\n",
        "plt.xlabel('Predicted Label', fontsize=14)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9zxqR2kLuix0"
      },
      "source": [
        "The following code gives us an overview for each case, pointing out both the precision, recall and f1-score metrics. It is possible to notice that the values in general are very close, which indicates that both models are capable of handling the binary sentiment analysis task with close results, and both models presented an F1-score of 87%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7yyTex4tsjP",
        "outputId": "fa095995-aad7-4d81-ee8e-b3d726270b97"
      },
      "outputs": [],
      "source": [
        "cr_lstm = classification_report(y_test, pred_lstm)\n",
        "cr_cnn = classification_report(y_test, pred_cnn)\n",
        "print(cr_lstm)\n",
        "print(cr_cnn)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DxCeTLE9EjR6"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After completing this project, it was possible to conclude:\n",
        "\n",
        "- The use of CBOW to generate vectors of words used as Input of the networks makes the neural model itself easier and faster to train.\n",
        "- The word vectors generated by CBOW represent the words obtained well, despite the low accuracy for the analogy solution.\n",
        "- Both models - LSTM and CNN - presented similar result metrics for the binary sentiment analysis task of movie *reviews* (IMDB Dataset).\n",
        "- Although both models presented similar results, training the CNN was a more laborious process than for the LSTM and most of the time with inferior results.\n",
        "- The knowledge acquired through the discipline proves to be updated according to the state of the art and more than enough to develop its own applications."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
